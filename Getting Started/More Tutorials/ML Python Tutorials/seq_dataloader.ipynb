{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Sequential DataLoader to Create a Training Loop\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    :download:`Download the tutorial code <seq_dataloader.ipynb>`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. note::\n",
    "    This tutorial is using some features that are available only with our Professional plan."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this tutorial, we will learn how to load data in a sequential way via our classes :py:class:`metavision_ml.data.sequential_dataset.SequentialDataLoader` and :py:class:`metavision_ml.data.sequential_dataset.SequentialDataset`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from urllib.request import urlretrieve\n",
    "from functools import partial\n",
    "\n",
    "from metavision_ml.data import SequentialDataLoader\n",
    "from metavision_ml.data import box_processing as box_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "dataset_path = \"dataset_precomputed\"\n",
    "# a dictionary containing the correspondence map for class indices\n",
    "label_map_path = os.path.join(dataset_path, 'label_map_dictionary.json')\n",
    "\n",
    "# getting the data for this tutorial\n",
    "if not os.path.isdir(dataset_path):\n",
    "    if not os.path.exists(\"sample_dataset.zip\"):\n",
    "        urlretrieve(\"https://dataset.prophesee.ai/index.php/s/QFrGIKZ13fr1oQa/download\", filename=\"sample_dataset.zip\")\n",
    "    with ZipFile('sample_dataset.zip', 'r') as zipObj:\n",
    "        # Extract all the contents of zip file in current directory\n",
    "        zipObj.extractall()\n",
    "!ls \"sample_dataset.zip\" {dataset_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Suggestions on organizing your dataset**\n",
    "\n",
    "The data sample we provided here is only used for illustration purpose. In practice, we suggest you to separate train, test and validation data in distinct folders, using the following structure:\n",
    "\n",
    "```\n",
    "    dataset_folder/\n",
    "    ├── train/\n",
    "    │   ├── file_1.h5\n",
    "    │   ├── file_1_bbox.npy\n",
    "    │   ├── file_2.h5\n",
    "    │   ├── file_2_bbox.npy\n",
    "    ├── test/\n",
    "    │   ├── file_3.h5\n",
    "    │   ├── file_3_bbox.npy\n",
    "    │   ├── file_4.h5\n",
    "    │   ├── file_4_bbox.npy\n",
    "    ├── val/\n",
    "    │   ├── file_5.h5\n",
    "    │   ├── file_5_bbox.npy\n",
    "    ├── possibly a readme and some metadata file (JSON etc.)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note that when using the ``SequentialDataLoader``, we suggest to precompute the tensor features as explained in :ref:`our data preprocessing tutorials <chapter_ml_data_processing>`. This will reduce the computation time. However, :py:class:`metavision_ml.data.sequential_dataset.SequentialDataLoader` can also use ``DAT`` files directly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Labels\n",
    "\n",
    "In supervised training, in addition to the training data, we need ground truth labels as well. Depending on the type of training, the labels might come in very different formats. To facilitate training with various label formats, we provide a **template function** that can be used to write your own label loading functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see how this **template function** looks like in our ML module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metavision_ml.data.sequential_dataset import load_labels_stub\n",
    "help(load_labels_stub)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the function returns both a list of labels and a boolean mask indicating if the corresponding time bins are labeled or not. During training, this boolean mask will be used to filter out unlabeled time bins so that no loss will be computed on them."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. note::\n",
    "    Since our SequentialDataLoader deals with event-based data, the ground truth labels should be timestamped. This is required for playing labels synchronously with the event features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customize a Label Loading Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a function to load detection bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_load_boxes(metadata, batch_start_time, duration, tensor, **kwargs):\n",
    "\n",
    "    # we first load the events from file\n",
    "    box_events = box_api.load_box_events(metadata, batch_start_time, duration)\n",
    "    \n",
    "    # here, we just look in the class look up what is the corresponding number for each class \n",
    "    # in order to get contiguous class numbers for our training dataset.\n",
    "    class_lookup = kwargs['class_lookup']\n",
    "    box_events['class_id'] = class_lookup[box_events['class_id']]\n",
    "    \n",
    "    # We then split the box events into each time bin in a list of box event array\n",
    "    num_tbins = tensor.shape[0]\n",
    "    box_events = box_api.split_boxes(box_events, batch_start_time=batch_start_time, delta_t=duration // num_tbins, num_tbins=num_tbins)\n",
    "    # if all frames contain labels\n",
    "    all_frames_are_okay = np.ones((len(box_events)), dtype=np.bool)\n",
    "    return box_events, all_frames_are_okay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that the function above requires an additional argument: `class_lookup` compared to our **template function**. Therefore, we need to customize the function so that its signature is exactly the one we expect. You can use the [partial](https://docs.python.org/3/library/functools.html#functools.partial) function from the [functools](https://docs.python.org/3/library/functools.html) module to pass additional arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the labels of the class we want to load from the dataset\n",
    "wanted_keys = ['car', 'pedestrian', 'two wheeler']\n",
    "\n",
    "# create a look up table to get the lookup IDs from the selected classes\n",
    "class_lookup = box_api.create_class_lookup(label_map_path, wanted_keys)\n",
    "\n",
    "custom_load_boxes_fn = partial(custom_load_boxes, class_lookup=class_lookup)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. note::\n",
    "    For a more complete example, see the ``load_boxes`` function in the source code of ``metavision_ml/data/box_processing.py``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event-Based SequentialDataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before instantiating the ``SequentialDataLoader`` class, let's first define some input parameters, then pass our custom label loading function ``custom_load_boxes_fn``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(dataset_path, \"*.h5\"))[:2]\n",
    "preprocess_function_name = \"histo\"\n",
    "delta_t = 50000\n",
    "channels = 2  # histograms have two channels\n",
    "num_tbins = 3\n",
    "height, width = 360, 640\n",
    "batch_size = 2\n",
    "max_incr_per_pixel = 2.5\n",
    "array_dim = [num_tbins, channels, height, width]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instantiate the class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_dataloader = SequentialDataLoader(files, delta_t, preprocess_function_name, array_dim,\n",
    "                                      load_labels=custom_load_boxes_fn,\n",
    "                                      batch_size=batch_size, num_workers=0,\n",
    "                                      preprocess_kwargs={\"max_incr_per_pixel\": max_incr_per_pixel})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's iterate over the loaded data and visualize its metadata.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, batch in enumerate(seq_dataloader):\n",
    "    if index == 1: # we only visualize one example, remove it if you want to process all data\n",
    "        break\n",
    "    print(\"available keys: \", batch.keys(), \"\\n\") \n",
    "    print(\"input shape:\", batch[\"inputs\"].shape, \"\\n\")\n",
    "    print(\"metadata:\", batch[\"video_infos\"], \"\\n\")\n",
    "    print(\"box events: \", len(batch['labels']), \"lists (corresponding to the no. of time bins), each containing a batch sized lists :\", [len(labels) for labels in batch['labels']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, at each iteration ``SequentialDataLoader`` produces a dictionary, containing information of  `inputs`, `labels`, `mask_keep_memory`, `frame_is_labeled` and `video_infos`. \n",
    "\n",
    "The inputs are tensors of the shape $[T \\times N \\times C \\times H \\times N]$ instead of $[N \\times C \\times H \\times N]$, because we need to deal with the temporal information in our training, and it allows to process the data sequentially from the first time bin to the last. \n",
    "\n",
    "* T: number of time bins\n",
    "* N: batch size\n",
    "* C: feature size\n",
    "* H: height\n",
    "* W: width\n",
    "\n",
    "\n",
    "\n",
    "Similarly, the bounding boxes are organized in $T$ lists of $N$ nested lists, so that labels and tensor are indexed consistently. \n",
    "\n",
    "The ``mask_keep_memory`` is a binary tensor of length $N$, with value 0. indicating the beginning of a new recording. This is useful in case we want to reset memory between different recordings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's also take a closer look at those labels in one batch of the time bin.**\n",
    "\n",
    "For instance, bounding boxes in the 2nd time bin of the 1st batch are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['labels'][1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Utility of SequentialDataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class ``SequentialDataLoader`` provides a visualization method named ``show``. It can visualize batches of the ``SequentialDataLoader`` in parallel with openCV. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's visualize the frames we have just loaded.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ.get(\"DOC_DISPLAY\", \"ON\") != \"OFF\":\n",
    "    cv2.namedWindow('sequential_dataloader')\n",
    "    for frame in seq_dataloader.show():\n",
    "        cv2.imshow('sequential_dataloader', frame[..., ::-1])\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:\n",
    "            break\n",
    "    cv2.destroyWindow('sequential_dataloader')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The ``show()`` method can be called with a custom label visualization function so as to stream the labels together with the input data. Its signature should match the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_labels(frame, labels):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        frame (np.ndarray) frame of size height x width x 3\n",
    "        labels: label for one file and one tbin\n",
    "\n",
    "    Returns:\n",
    "        The input frame on which the labels were drawn.\n",
    "    \"\"\"\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For more information, check :py:class:`metavision_ml.detection_tracking.display_frame.draw_box_events` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's now visualize the batch data together with the labels.** \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This time we will use the predefined :py:class:`metavision_ml.data.box_processing.load_boxes` function in the ML module to **load** the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_boxes_fn = partial(box_api.load_boxes, class_lookup=class_lookup)\n",
    "\n",
    "seq_dataloader = SequentialDataLoader(files, delta_t, preprocess_function_name, array_dim, load_labels=load_boxes_fn,\n",
    "                                      batch_size=batch_size, num_workers=0, preprocess_kwargs={\"max_incr_per_pixel\": max_incr_per_pixel})\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We will also use the predefined :py:class:`metavision_ml.detection_tracking.display_frame.draw_box_events` function to **show** the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metavision_ml.detection_tracking.display_frame import draw_box_events\n",
    "\n",
    "label_map = ['background'] + wanted_keys\n",
    "\n",
    "# adding box visualization. Notice how here again we rely on partial.\n",
    "viz_labels = partial(draw_box_events, label_map=label_map)\n",
    "\n",
    "if os.environ.get(\"DOC_DISPLAY\", \"ON\") != \"OFF\":\n",
    "    cv2.namedWindow('sequential_dataloader')\n",
    "    for frame in seq_dataloader.show(viz_labels):\n",
    "        cv2.imshow('sequential_dataloader', frame[..., ::-1])\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:\n",
    "            break\n",
    "    cv2.destroyWindow('sequential_dataloader')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop Example\n",
    "\n",
    "The data loader presented in this tutorial can be used to create a custom training loop.\n",
    "The following is the pseudo-code you can use to train you own event-based models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "for data in seq_dataloader:\n",
    "    # we first need to reset the memory for each new sequence in the batch and detach the gradients\n",
    "    # detaching the gradients prevents the computational graph to be as long as the full sequence.\n",
    "    # This is called *truncated backpropagation*.\n",
    "    net.reset(data['mask_keep_memory'])\n",
    "    \n",
    "    # clear the optimiser\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # we compute the predictions chronologically. This is the forward pass.\n",
    "    predictions = []\n",
    "    for batch in data['inputs']:\n",
    "        predictions.append(net.forward(batch))\n",
    "    predictions = torch.stack(predictions)\n",
    "        \n",
    "    # loss is computed only during relevant timestamps.\n",
    "    loss = compute_loss(predictions[data[\"frame_is_labeled\"]], data['targets'][data[\"frame_is_labeled\"]])\n",
    "\n",
    "    # we then compute the backward pass and update the networks weights.\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CDProcessorDataLoader\n",
    "\n",
    "Above Implementation is based on the Pytorch Dataset (Map-Style Dataset with __get_item__ function to override). We present here an alternative implementation based on Pytorch IterableDataset. The advantage is for cases where frequent file seeking is costly or not possible. With it you can stream .raw files directly, without having to convert them to dat or h5 files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metavision_ml.data.cd_processor_dataset import CDProcessorDataLoader\n",
    "from metavision_core.utils import get_sample\n",
    "\n",
    "# we grab a folder of .raw files\n",
    "# if the file doesn't exist, it will be downloaded from Prophesee's public sample server \n",
    "files = [\"driving_sample.raw\",\"hand_spinner.raw\", \"spinner.raw\", \"80_balls.raw\"]\n",
    "\n",
    "for file in files:\n",
    "    get_sample(file)\n",
    "    assert os.path.isfile(file)\n",
    "\n",
    "dataloader = CDProcessorDataLoader(\n",
    "    files,\n",
    "    mode='n_events',\n",
    "    delta_t=0,\n",
    "    n_events=10000,\n",
    "    max_duration=10000000,\n",
    "    preprocess_function_name=\"diff\",\n",
    "    height=240,\n",
    "    width=320,\n",
    "    num_tbins=5,\n",
    "    batch_size=4,\n",
    "    num_workers=2,\n",
    "    load_labels=None,\n",
    "    padding_mode='zeros')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metavision_ml.data.sequential_dataset_common import show_dataloader\n",
    "\n",
    "show = show_dataloader(\n",
    "    dataloader,\n",
    "    dataloader.height,\n",
    "    dataloader.width,\n",
    "    dataloader.batch_size,\n",
    "    dataloader.get_vis_func(),\n",
    "    None)\n",
    "\n",
    "if os.environ.get(\"DOC_DISPLAY\", \"ON\") != \"OFF\":\n",
    "    cv2.namedWindow('stream_dataloader')\n",
    "    for frame in show:\n",
    "        cv2.imshow('stream_dataloader', frame[..., ::-1])\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:\n",
    "            break\n",
    "    cv2.destroyWindow('stream_dataloader')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. note::\n",
    "    This tutorial was created using `Jupiter Notebooks <https://jupyter.org/>`_\n",
    "\n",
    "    :download:`Download the tutorial code <seq_dataloader.ipynb>`."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
