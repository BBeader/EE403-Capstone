{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Python bindings\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "    :download:`Download the tutorial code <metavision_sdk_ml_bindings.ipynb>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metavision SDK provides Python bindings of the algorithms implemented in C++.\n",
    "\n",
    "This tutorial presents:\n",
    "\n",
    "  - How to load and create numpy arrays of events\n",
    "  - How to do geometrical transformation\n",
    "  - How to apply noise/ROI filter algorithm\n",
    "  - How to process events to generate tensor for neural network algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the tutorial, events are set in a numpy array for the Python bindings and visualized with `matplotlib` as an example.\n",
    "\n",
    "Let's start with some initial import that we be needed in multiple sections of this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [11, 7]\n",
    "\n",
    "from metavision_sdk_core import BaseFrameGenerationAlgorithm\n",
    "import metavision_sdk_ml\n",
    "\n",
    "def are_events_equal(ev1, ev2):\n",
    "    \"\"\"Simple functions comparing event vector field by fields\"\"\"\n",
    "    return ev1.size == ev2.size and min(np.allclose(ev1[name], ev2[name]) for name in ev1.dtype.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading events\n",
    "\n",
    "Before being able to execute algorithms from the SDK, a numpy array of CD events is required.\n",
    "\n",
    "An empty array of events can be generated as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metavision_sdk_base\n",
    "empty_array = np.zeros(2, metavision_sdk_base.EventCD)\n",
    "\n",
    "print(\"%r\" % empty_array)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "An array of events can also be obtained by reading a RAW file or by opening an event-based camera.\n",
    "\n",
    "To load events interactively,\n",
    ":ref:`RawReader <chapter_sdk_python_api_io>` is used in this notebook. Its usage is described in the :doc:`File Loading Tutorial <../../core/tutorials/raw_dat_loading>`. The loaded events can be directly used by the different algorithms like we will see in the following sections.\n",
    "\n",
    ".. note::\n",
    "\n",
    "    To process entire RAW and DAT files consider using :ref:`EventsIterator <chapter_sdk_python_api_io>`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from metavision_core.event_io import RawReader\n",
    "from metavision_core.utils import get_sample\n",
    "\n",
    "sequence_filename_raw = \"spinner.raw\"\n",
    "# if the file doesn't exist, it will be downloaded from Prophesee's public sample server \n",
    "get_sample(sequence_filename_raw, folder=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometrical Preprocessing\n",
    "\n",
    "### Transpose\n",
    "\n",
    "Swap `x` and `y` coordinates of an event stream.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The following code instantiates the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metavision_sdk_cv\n",
    "transpose = metavision_sdk_cv.TransposeEventsAlgorithm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the events from the RAW files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"before transpose.process(): \")\n",
    "mv_raw = RawReader(sequence_filename_raw)\n",
    "\n",
    "ev_0_500 = mv_raw.load_delta_t(500)\n",
    "print(ev_0_500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now transpose the events into a new buffer and check that the event coordinates are transposed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose without changing the input array (create a copy)\n",
    "ev_0_500_transposed = transpose.get_empty_output_buffer()\n",
    "transpose.process_events(ev_0_500, ev_0_500_transposed)\n",
    "assert not are_events_equal(ev_0_500_transposed.numpy(), ev_0_500)\n",
    "print(ev_0_500_transposed.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the previous buffer is unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"after transpose.process(): \")\n",
    "print(ev_0_500)  # unchanged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid data copy and allocation, the function `process_events_()` can be used to process the events inside the provided buffer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose in-place\n",
    "transpose.process_events_(ev_0_500)\n",
    "assert are_events_equal(ev_0_500_transposed.numpy(), ev_0_500)\n",
    "print(\"After transpose.process_events_(): \")\n",
    "print(ev_0_500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FlipX / FlipY\n",
    "\n",
    "FlipX applies a vertical line symmetry in the middle of the image to transform all events coordinates.\n",
    "Whereas FlipY applies a horizontal one.\n",
    " \n",
    "Before flipping the coordinates, let's load some events from the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_raw = RawReader(sequence_filename_raw)\n",
    "\n",
    "ev = mv_raw.load_delta_t(600)\n",
    "print(ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate FlipX algorithm and apply it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metavision_sdk_core\n",
    "sensor_width = mv_raw.get_size()[1]\n",
    "print(\"sensor width: %s every x coordinate should be now x - sensor_width - 1\" % sensor_width)\n",
    "flipX = metavision_sdk_core.FlipXAlgorithm(sensor_width - 1)\n",
    "ev_flipX_buffer = flipX.get_empty_output_buffer()\n",
    "flipX.process_events(ev, ev_flipX_buffer)\n",
    "print(ev_flipX_buffer.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate FlipY algorithm and apply it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_height = mv_raw.get_size()[0]\n",
    "\n",
    "print(\"sensor height: %s every y coordinate should be now y - sensor_height - 1\" % sensor_height)\n",
    "\n",
    "flipY = metavision_sdk_core.FlipYAlgorithm(sensor_height - 1)\n",
    "ev_flipY_buffer = flipY.get_empty_output_buffer()\n",
    "flipY.process_events(ev, ev_flipY_buffer)\n",
    "print(ev_flipY_buffer.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the transpose algorithm, the buffer can be processed in place with the function `process_events_()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipX.process_events_(ev)\n",
    "flipY.process_events_(ev)\n",
    "print(ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event filtering\n",
    "\n",
    "### Region Of Interest (ROI)\n",
    "\n",
    "The Region Of Interest Algorithm filters out all events that are outside of a rectangular region of interest.\n",
    "The filter takes two coordinates as arguments: one coordinate per rectangle corner (the top left and the right bottom corners).\n",
    "\n",
    "In the following code, the RoiFilter is instantiated to remove all events outside of a box represented by its corners coordinates:\n",
    "\n",
    "  - top left: (200, 100);\n",
    "  - bottom right: (320, 200)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = metavision_sdk_core.RoiFilterAlgorithm(x0=100, y0=255, x1=200, y1=320)\n",
    "ev_filtered_buffer = roi.get_empty_output_buffer()\n",
    "\n",
    "mv_raw = RawReader(sequence_filename_raw)\n",
    "\n",
    "ev = mv_raw.load_delta_t(1000000)\n",
    "\n",
    "roi.process_events(ev, ev_filtered_buffer)\n",
    "ev_filtered = ev_filtered_buffer.numpy()\n",
    "print(ev_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show that all the events are in the provided ROI is easier to check with an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = mv_raw.get_size()\n",
    "frame = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "BaseFrameGenerationAlgorithm.generate_frame(ev_filtered, frame)\n",
    "image = plt.imshow(frame[..., ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise Filters: Trail / STC\n",
    "\n",
    "Trail and STC filters are used to reduce the number of events produced by the camera.\n",
    "\n",
    "First, load some events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_raw = RawReader(sequence_filename_raw)\n",
    "height, width = mv_raw.get_size()\n",
    "mv_raw.seek_time(2e6)\n",
    "\n",
    "ev = mv_raw.load_delta_t(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the noise filtering algorithms and apply them on the buffer of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail = metavision_sdk_cv.TrailFilterAlgorithm(width=width, height=height, threshold=10000)\n",
    "ev_trail_buf = trail.get_empty_output_buffer()\n",
    "trail.process_events(ev, ev_trail_buf)\n",
    "ev_trail_np = ev_trail_buf.numpy()\n",
    "\n",
    "stc = metavision_sdk_cv.SpatioTemporalContrastAlgorithm(width=width, height=height, threshold=10000)\n",
    "ev_stc_buf = stc.get_empty_output_buffer()\n",
    "stc.process_events(ev, ev_stc_buf)\n",
    "ev_stc_np = ev_stc_buf.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the behavior of the algorithms, the generated frames are displayed side by side with the number of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [18, 7]\n",
    "_, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "ax1.set_title(\"unfiltered : {} events\".format(len(ev)))\n",
    "BaseFrameGenerationAlgorithm.generate_frame(ev, frame)\n",
    "ax1.imshow(frame[..., ::-1])\n",
    "ax2.set_title(\"filtered with trail : {} events\".format(len(ev_trail_np)))\n",
    "BaseFrameGenerationAlgorithm.generate_frame(ev_trail_np, frame)\n",
    "ax2.imshow(frame[..., ::-1])\n",
    "ax3.set_title(\"filtered with STC : {} events\".format(len(ev_stc_np)))\n",
    "BaseFrameGenerationAlgorithm.generate_frame(ev_stc_np, frame)\n",
    "image = ax3.imshow(frame[..., ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event preprocessing : CDProcessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ":ref:`CDProcessing <chapter_sdk_ml_python_bindings_api>` is a C++ implementation of the function described in :doc:`the event preprocessing tutorial <../data_processing/event_preprocessing>`.\n",
    "\n",
    "Note that those functions are only available to Metavision Professional users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the visualization functions from metavision_ml can be used.\n",
    "from metavision_ml.preprocessing import viz_histo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a `CDProcessing` function with:\n",
    "\n",
    "  * `histo`\n",
    "  * delta_t = 50ms\n",
    "  * network input size as a half of the size of the event_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_raw = RawReader(sequence_filename_raw)\n",
    "height, width = mv_raw.get_size()\n",
    "mv_raw.seek_time(3e6)\n",
    "\n",
    "ev = mv_raw.load_delta_t(50000)\n",
    "\n",
    "cdproc = metavision_sdk_ml.CDProcessing.create_CDProcessingHisto(delta_t=50000, \n",
    "                             network_input_width=width // 2,\n",
    "                             network_input_height=height // 2,\n",
    "                             event_input_width=width, event_input_height=height)\n",
    "\n",
    "frame_buffer = cdproc.init_output_tensor()\n",
    "cdproc.process_events(3000000, ev, frame_buffer)\n",
    "print(\"frame_buffer shape        : \", frame_buffer.shape)\n",
    "print(\"number of non-zero values : \", np.sum(frame_buffer != 0))\n",
    "print(\"set of unique values      :\\n\", np.around(np.unique(frame_buffer), decimals=2))\n",
    "plt.imshow(viz_histo(frame_buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = mv_raw.load_delta_t(50000)\n",
    "\n",
    "# reset and reuse the frame_buffer\n",
    "frame_buffer.fill(0)\n",
    "cdproc.process_events(3050000, ev, frame_buffer)\n",
    "print(\"frame_buffer shape        : \", frame_buffer.shape)\n",
    "print(\"number of non-zero values : \", np.sum(frame_buffer != 0))\n",
    "print(\"set of unique values      :\\n\", np.around(np.unique(frame_buffer), decimals=2))\n",
    "plt.imshow(viz_histo(frame_buffer))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. note::\n",
    "    This tutorial was created using `Jupiter Notebooks <https://jupyter.org/>`_\n",
    "\n",
    "    :download:`Download the tutorial code <metavision_sdk_ml_bindings.ipynb>`."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
